{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaiYcI1AAEocH21r3DBszL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ac291c026d147b38fffb46968e5fea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1b53bfbd829438a9a1c818b300ab6cd",
              "IPY_MODEL_a7d755451c3442cdba11eb09c55bc175",
              "IPY_MODEL_8cd0b08ecb3b4f81834748ed4b2c6be3"
            ],
            "layout": "IPY_MODEL_b66c5bae01f34ca2ab73daf3ba8516d4"
          }
        },
        "d1b53bfbd829438a9a1c818b300ab6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e230bbe9044c9eaa610a9e0a7d14a7",
            "placeholder": "​",
            "style": "IPY_MODEL_5729dd26f8ef4007a44b74f52b53a02d",
            "value": "100%"
          }
        },
        "a7d755451c3442cdba11eb09c55bc175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f27a90362fac469a8d3557fa22883eb3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c3f3f9d67164aefbaa98c1c12e6e579",
            "value": 1
          }
        },
        "8cd0b08ecb3b4f81834748ed4b2c6be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d848c226bd4040cb81d5c23b72f5a756",
            "placeholder": "​",
            "style": "IPY_MODEL_fc54258de05540b69375799cc016ebea",
            "value": " 1/1 [00:00&lt;00:00,  9.49ba/s]"
          }
        },
        "b66c5bae01f34ca2ab73daf3ba8516d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e230bbe9044c9eaa610a9e0a7d14a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5729dd26f8ef4007a44b74f52b53a02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f27a90362fac469a8d3557fa22883eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3f3f9d67164aefbaa98c1c12e6e579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d848c226bd4040cb81d5c23b72f5a756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc54258de05540b69375799cc016ebea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b3951c2304a4ff2a9eefd3aa49d9e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5895478c8efe48e29405ef5a37409844",
              "IPY_MODEL_4faa1d60cc224557aa14dcc6586b3e65",
              "IPY_MODEL_d7e1f676960b4679a736595a99a7b491"
            ],
            "layout": "IPY_MODEL_06809106e67f4e38b51c6f2df8293a2e"
          }
        },
        "5895478c8efe48e29405ef5a37409844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb39102efe541e2a433a0800aaff26a",
            "placeholder": "​",
            "style": "IPY_MODEL_065292aae3fc4b07846129ce24109733",
            "value": "100%"
          }
        },
        "4faa1d60cc224557aa14dcc6586b3e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc9ae86dfba84d68adf7c76c478b770d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae995f361d1347f88092b939bf42d929",
            "value": 1
          }
        },
        "d7e1f676960b4679a736595a99a7b491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbaf9d7e58c406d80cf141bea9af332",
            "placeholder": "​",
            "style": "IPY_MODEL_34ce02b448cf448888a851f1dc5f5ecd",
            "value": " 1/1 [00:00&lt;00:00, 16.43ba/s]"
          }
        },
        "06809106e67f4e38b51c6f2df8293a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb39102efe541e2a433a0800aaff26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "065292aae3fc4b07846129ce24109733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc9ae86dfba84d68adf7c76c478b770d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae995f361d1347f88092b939bf42d929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fbaf9d7e58c406d80cf141bea9af332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ce02b448cf448888a851f1dc5f5ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharathpbharath/BackgroundGenerator/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train BERT from Scratch using Transformers in Python**"
      ],
      "metadata": {
        "id": "W2ZF596zbz2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets transformers==4.11.2 sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dYUMApTdVfg",
        "outputId": "e08c6e05-4395-4b35-c03f-9b0d9dce3eea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.1)\n",
            "Requirement already satisfied: transformers==4.11.2 in /usr/local/lib/python3.7/dist-packages (4.11.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (0.0.53)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (0.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.2) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.2) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.11.2) (3.0.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.2) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.2) (2.10)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.2) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.2) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import *\n",
        "from transformers import *\n",
        "from tokenizers import *\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "eQZDY2dncAEP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and prepare cc_news dataset\n",
        "dataset = load_dataset(\"cc_news\", split=\"train[0:10]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f38o8Mg0dpie",
        "outputId": "fcb1b719-7484-43d3-9a87-8a7eeef0a4c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset cc_news (/root/.cache/huggingface/datasets/cc_news/plain_text/1.0.0/ae469e556251e6e7e20a789f93803c7de19d0c4311b6854ab072fecb4e401bd6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset))\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaywvQJPjpJL",
        "outputId": "910f1c9b-a565-493f-e1f8-ce6bdf599435"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n",
            "Dataset({\n",
            "    features: ['title', 'text', 'domain', 'date', 'description', 'url', 'image_url'],\n",
            "    num_rows: 10\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into training (90%) and testing (10%)\n",
        "d = dataset.train_test_split(test_size=0.1)\n",
        "d[\"train\"], d[\"test\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-A590qlfPGD",
        "outputId": "a06fb736-9a51-4159-e534-5ac91f18ccc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['title', 'text', 'domain', 'date', 'description', 'url', 'image_url'],\n",
              "     num_rows: 9\n",
              " }), Dataset({\n",
              "     features: ['title', 'text', 'domain', 'date', 'description', 'url', 'image_url'],\n",
              "     num_rows: 1\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in d[\"train\"][\"text\"][:3]:\n",
        "  print(t)\n",
        "  print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kST-wQKPfW8l",
        "outputId": "ac733702-ffa1-4f95-a75c-70180cc92472"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Philadelphia Eagles and the New England Patriots aren't the only teams bringing Super Bowl entertainment this week. To celebrate game day (and cheer on their region's respective teams), the dancers of Pennsylvania Ballet and Boston Ballet took a break from their usual rehearsals to perform some Super Bowl-themed choreography.\n",
            "Dressed in their Eagles green, the PAB dancers performed a fast-paced routine full of fouetté turns, sky-high jumps and some swan arms (because they're known as the birds, get it?).\n",
            "But Boston Ballet also decided to get in on the fun—with five Super Bowl wins, they're used to seeing their team in the big game. Sharing their own video on Facebook, which stars principal Paul Craig and soloist Derek Dunn, Boston Ballet threw in a few Balanchine tricks thanks to some props from Prodigal Son.\n",
            "This is officially our new favorite way to get in on the football fun.\n",
            "==================================================\n",
            "Literary Roots\n",
            "E.T.A. Hoffmann, a German writer, penned the eerie and dark tale \"Nutcracker and Mouse King\" in 1816. About 30 years later, the French writer Alexandre Dumas took the Nutcracker story into his own hands, lightening things up and softening the character descriptions. Dumas even cheered up the name of the protagonist. \"Marie Stahlbaum\" (meaning \"steel tree,\" representing the repressive family Marie found herself in, which led her imagination to run wild) became \"Clara Silberhaus\" (translated to \"silver house,\" a magnificent home filled with shiny magic.)\n",
            "Snowflakes of the original cast, \"The Nutcracker\" at the Mariinsky Theatre, 1892. Photo by Walter E. Owen, Courtesy Dance Magazine Archives.\n",
            "From Page to Stage\n",
            "In 1892 St. Petersburg, choreographer Marius Petipa and composer Pyotr Ilyich Tchaikovsky pulled the story off the page and onto the stage of the Mariinsky Theatre. But Petipa fell ill while choreographing The Nutcracker and handed his duties over to his assistant, Lev Ivanov. Critics at the 1892 premiere were not pleased. Balletomanes felt the work to be uneven, and lamented the lack of a main ballerina in the first act. Many thought that the story was too light compared to historically based stories.\n",
            "Out of Russia\n",
            "Despite its initial reception, the ballet survived, partially due to the success of Tchaikovsky's score. Performances were scarce, though, as the Russian Revolution scattered its original dancers. The Nutcracker's first major exposure outside of Russia took place in London in 1934. Former Mariinsky ballet master Nikolas Sergeyev was tasked with staging Petipa's story ballets on the Vic-Wells Ballet (today The Royal Ballet) from the original notation. The notes were incomplete and difficult to read, yet Sergeyev persisted, and The Nutcracker made it to the stage.\n",
            "Dancers from ballet Russe de Monte Carlo in \"The Nutcracker\" pas de deux. Photo Courtesy Dance Magazine Archives.\n",
            "An American Premiere\n",
            "The Ballet Russe de Monte Carlo brought an abridged version of The Nutcracker to the U.S. in 1940. Over the next decade, the company toured the ballet extensively, exposing it to audiences nationwide.\n",
            "Willam Christensen (center) with his brothers Lew and Harold. Photo Courtesy San Francisco Ballet.\n",
            "Across the Country…\n",
            "In 1944, San Francisco Ballet founding artistic director Willam Christensen choreographed the U.S.'s first full-length Nutcracker. Christensen later founded Ballet West, which continues to perform his version of The Nutcracker each year.\n",
            "Balanchine rehearsing the snow scene with NYCB. Photo by Frederick Melton, Courtesy Dance Magazine Archives.\n",
            "A Christmas Staple\n",
            "Though the ballet's popularity was already growing, some historians suggest that George Balanchine was the first to irretrievably link the work to the holidays. As dance critic Robert Greskovic puts it, Balanchine was \"responsible for making the ballet a fixture of the Christmas season and of a ballet company's repertory.\" New York City Ballet first presented Balanchine's Nutcracker in February of 1954 but quickly recognized its holiday appeal and moved the ballet to December for the following year.\n",
            "Nutcracker All Over\n",
            "As regional ballet companies sprouted around the country, The Nutcracker became a staple.Today it's a holiday tradition that keeps families coming back year after year; its mass appeal keeps ballet in mainstream culture. Many companies attract audiences by infusing the classic with their own regional heritage: Christopher Wheeldon's Nutcracker for the Joffrey Ballet is set at Chicago's 1893 world's fair and The Washington Ballet serves a dose of American history with characters such as George Washington and King George III.\n",
            "George Washington in The Washington Ballet's Nutcracker.\" Photo by Carol Pratt, Courtesy The Washington Ballet.\n",
            "The Nutcracker also serves as the financial backbone of companies nationwide. Last year San Francisco Ballet sold a total of 87,926 tickets to the holiday ballet and Boston Ballet sold a total of 92,907. Despite its humble roots, The Nutcracker is now the show that companies rely on to put on inventive and cutting-edge works throughout the rest of the year.\n",
            "More secrets and surprises…\n",
            "According to dance historian Doug Fullington, in the original 1892 scenario the Nutcracker has two sisters who graciously welcome Clara to the Land of Sweets with warm hugs.\n",
            "Pennsylvania Ballet's Craig Wasserman in the Candy Cane variation. Photo by Alexander Iziliaev, Courtesy Pennsylvania Ballet.\n",
            "The Candy Cane variation (danced to the Russian Trepak music) was choreographed by its original 1892 dancer, Alexandre Shiryaev. Dance critic Mindy Aloff says that Shiryaev was \"possibly the first practitioner of hand-drawn animation; he notated his choreography in sequential drawings that could be projected to show the dance in movement.\" Balanchine included Shiryaev's original choreography in his Nutcracker.\n",
            "The ethereal twinkling sound in the Sugar Plum Fairy's solo comes from the celesta, a rare instrument Tchaikovsky heard in France. \"He had one sent to him essentially in secret,\" says Fullington.\n",
            "Balanchine was given a budget of $40,000 for his 1954 premiere and, according to Aloff, he spent $25,000 on the Christmas tree alone. When asked if he could do without the tree Balanchine responded, \"[The ballet] is the tree.\" Today, New York City Ballet's tree weighs one ton and can reach a full height of 41 feet.\n",
            "1892 \"Nutcracker\" costume sketch by Ivan Vsevolozhsky of the Sugar Plum Fairy's retinue. Courtesy Peter Koppers.\n",
            "Choreographic notations suggest that the Cavalier's variation was originally danced by a retinue of eight female fairies representing things like fruit, flowers and dreams. According to Fullington, Pavel Gerdt, the dancer who created the role, was likely too old to dance the variation himself.\n",
            "NYCB's Brittany Pollack and Chase Finlay in the grand pas de deux toe slide. Photo by Paul Kolnik, Courtesy New York City Ballet.\n",
            "In Balanchine's grand pas de deux, the lead ballerina holds an arabesque while gliding across the stage on pointe, pulled by her gallant prince. According to Fullington, Balanchine took this slide from Ivanov's original choreography.\n",
            "The Sugar Plum Fairy's prince's original name was \"Prince Coqueluche.\" Meaning \"whooping cough\" in French, it likely referred to a lozenge candy.\n",
            "NYCB's Unity Phelan and Silas Farley in Karinska's Hot Chocolate costumes. Photo by Paul Kolnik, Courtesy New York City Ballet.\n",
            "==================================================\n",
            "There's a surprising twist to Regina Willoughby's last season with Columbia City Ballet: It's also her 18-year-old daughter Melina's first season with the company. Regina, 40, will retire from the stage in March, just as her daughter starts her own career as a trainee. But for this one season, they're sharing the stage together.\n",
            "Performing Side-By-Side In The Nutcracker\n",
            "Regina and Melina are not only dancing in the same Nutcracker this month, they're onstage at the same time: Regina is doing Snow Queen, while Melina is in the snow corps, and they're both in the Arabian divertissement. \"It's very surreal to be dancing it together,\" says Regina. \"I don't know that I ever thought Melina would take ballet this far.\"\n",
            "Left: Regina and Melina with another company member post-snow scene in 2003. Right: The pair post-snow scene in 2017 (in the same theater)\n",
            "Keep reading at dancemagazine.com.\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to train the tokenizer from scratch (especially if you have custom\n",
        "# dataset loaded as datasets object), then run this cell to save it as files\n",
        "# but if you already have your custom data as text files, there is no point using this\n",
        "def dataset_to_text(dataset, output_filename=\"data.txt\"):\n",
        "  \"\"\"Utility function to save dataset text to disk,\n",
        "  useful for using the texts to train the tokenizer \n",
        "  (as the tokenizer accepts files)\"\"\"\n",
        "  with open(output_filename, \"w\") as f:\n",
        "    for t in dataset[\"text\"]:\n",
        "      print(t, file=f)\n",
        "\n",
        "# save the training set to train.txt\n",
        "dataset_to_text(d[\"train\"], \"train.txt\")\n",
        "# save the testing set to test.txt\n",
        "dataset_to_text(d[\"test\"], \"test.txt\")"
      ],
      "metadata": {
        "id": "V1ZEycDWfnRP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens = [\n",
        "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
        "]\n",
        "# if you want to train the tokenizer on both sets\n",
        "# files = [\"train.txt\", \"test.txt\"]\n",
        "# training the tokenizer on the training set\n",
        "files = [\"train.txt\"]\n",
        "# 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
        "vocab_size = 30_522\n",
        "# maximum sequence length, lowering will result to faster training (when increasing batch size)\n",
        "max_length = 512\n",
        "# whether to truncate\n",
        "truncate_longer_samples = True"
      ],
      "metadata": {
        "id": "QL_zA4DygUt6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the WordPiece tokenizer\n",
        "tokenizer = BertWordPieceTokenizer()\n",
        "# train the tokenizer\n",
        "tokenizer.train(files=files, vocab_size=vocab_size, special_tokens=special_tokens)\n",
        "# enable truncation up to the maximum 512 tokens\n",
        "tokenizer.enable_truncation(max_length=max_length)"
      ],
      "metadata": {
        "id": "jvA_fZLhgeo4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"pretrained-bert\""
      ],
      "metadata": {
        "id": "wZsJmosAglUy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make the directory if not already there\n",
        "if not os.path.isdir(model_path):\n",
        "  os.mkdir(model_path)\n",
        "# save the tokenizer  \n",
        "tokenizer.save_model(model_path)\n",
        "# dumping some of the tokenizer config to config file, \n",
        "# including special tokens, whether to lower case and the maximum sequence length\n",
        "with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n",
        "  tokenizer_cfg = {\n",
        "      \"do_lower_case\": True,\n",
        "      \"unk_token\": \"[UNK]\",\n",
        "      \"sep_token\": \"[SEP]\",\n",
        "      \"pad_token\": \"[PAD]\",\n",
        "      \"cls_token\": \"[CLS]\",\n",
        "      \"mask_token\": \"[MASK]\",\n",
        "      \"model_max_length\": max_length,\n",
        "      \"max_len\": max_length,\n",
        "  }\n",
        "  json.dump(tokenizer_cfg, f)"
      ],
      "metadata": {
        "id": "bl2wBjO8gp-L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when the tokenizer is trained and configured, load it as BertTokenizerFast\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "I3nWFGiSgt7a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_with_truncation(examples):\n",
        "  \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
        "  return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length, return_special_tokens_mask=True)\n",
        "\n",
        "def encode_without_truncation(examples):\n",
        "  \"\"\"Mapping function to tokenize the sentences passed without truncation\"\"\"\n",
        "  return tokenizer(examples[\"text\"], return_special_tokens_mask=True)\n",
        "\n",
        "# the encode function will depend on the truncate_longer_samples variable\n",
        "encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
        "\n",
        "# tokenizing the train dataset\n",
        "train_dataset = d[\"train\"].map(encode, batched=True)\n",
        "# tokenizing the testing dataset\n",
        "test_dataset = d[\"test\"].map(encode, batched=True)\n",
        "if truncate_longer_samples:\n",
        "  # remove other columns and set input_ids and attention_mask as \n",
        "  train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "  test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "else:\n",
        "  test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])\n",
        "  train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])\n",
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "5ac291c026d147b38fffb46968e5fea5",
            "d1b53bfbd829438a9a1c818b300ab6cd",
            "a7d755451c3442cdba11eb09c55bc175",
            "8cd0b08ecb3b4f81834748ed4b2c6be3",
            "b66c5bae01f34ca2ab73daf3ba8516d4",
            "a0e230bbe9044c9eaa610a9e0a7d14a7",
            "5729dd26f8ef4007a44b74f52b53a02d",
            "f27a90362fac469a8d3557fa22883eb3",
            "9c3f3f9d67164aefbaa98c1c12e6e579",
            "d848c226bd4040cb81d5c23b72f5a756",
            "fc54258de05540b69375799cc016ebea",
            "0b3951c2304a4ff2a9eefd3aa49d9e14",
            "5895478c8efe48e29405ef5a37409844",
            "4faa1d60cc224557aa14dcc6586b3e65",
            "d7e1f676960b4679a736595a99a7b491",
            "06809106e67f4e38b51c6f2df8293a2e",
            "fdb39102efe541e2a433a0800aaff26a",
            "065292aae3fc4b07846129ce24109733",
            "fc9ae86dfba84d68adf7c76c478b770d",
            "ae995f361d1347f88092b939bf42d929",
            "8fbaf9d7e58c406d80cf141bea9af332",
            "34ce02b448cf448888a851f1dc5f5ecd"
          ]
        },
        "id": "7RCqeDOPgxul",
        "outputId": "6ad0b93a-5a0a-4fb0-e435-8ff16618ddbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ac291c026d147b38fffb46968e5fea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b3951c2304a4ff2a9eefd3aa49d9e14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['title', 'text', 'domain', 'date', 'description', 'url', 'image_url', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
              "     num_rows: 9\n",
              " }), Dataset({\n",
              "     features: ['title', 'text', 'domain', 'date', 'description', 'url', 'image_url', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
              "     num_rows: 1\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main data processing function that will concatenate all texts from our dataset and generate chunks of\n",
        "# max_seq_length.\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= max_length:\n",
        "        total_length = (total_length // max_length) * max_length\n",
        "    # Split by chunks of max_len.\n",
        "    result = {\n",
        "        k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result\n",
        "# Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a\n",
        "# remainder for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value\n",
        "# might be slower to preprocess.\n",
        "#\n",
        "# To speed up this part, we use multiprocessing. See the documentation of the map method for more information:\n",
        "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map\n",
        "if not truncate_longer_samples:\n",
        "  train_dataset = train_dataset.map(group_texts, batched=True, batch_size=2_000,\n",
        "                                    desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "  test_dataset = test_dataset.map(group_texts, batched=True, batch_size=2_000,\n",
        "                                  num_proc=4, desc=f\"Grouping texts in chunks of {max_length}\")"
      ],
      "metadata": {
        "id": "OHwOjH1ckj2a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model with the config\n",
        "model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length)\n",
        "model = BertForMaskedLM(config=model_config)"
      ],
      "metadata": {
        "id": "FSY6E-rJVwnT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the data collator, randomly masking 20% (default is 15%) of the tokens for the Masked Language\n",
        "# Modeling (MLM) task\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "k2uNx1B7V28w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory to where save model checkpoint\n",
        "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
        "    overwrite_output_dir=True,      \n",
        "    num_train_epochs=10,            # number of training epochs, feel free to tweak\n",
        "    per_device_train_batch_size=10, # the training batch size, put it as high as your GPU memory fits\n",
        "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
        "    per_device_eval_batch_size=64,  # evaluation batch size\n",
        "    logging_steps=500,             # evaluate, log and save model checkpoints every 1000 step\n",
        "    save_steps=500,\n",
        "    # load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
        "    # save_total_limit=3,           # whether you don't have much space so you let only 3 model weights saved in the disk\n",
        ")"
      ],
      "metadata": {
        "id": "qx34fYicV4o-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the trainer and pass everything to it\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "uASLNa9KV8Dm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "U5qysnHLV_Jy",
        "outputId": "525c8688-7398-488a-a11a-b8d72016607b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: domain, text, url, image_url, description, title, special_tokens_mask, date.\n",
            "***** Running training *****\n",
            "  Num examples = 9\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 10\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 80\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 09:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10, training_loss=1.2154052734375, metrics={'train_runtime': 630.7599, 'train_samples_per_second': 0.143, 'train_steps_per_second': 0.016, 'total_flos': 23688433152000.0, 'train_loss': 1.2154052734375, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model checkpoint\n",
        "model = BertForMaskedLM.from_pretrained(os.path.join(model_path))\n",
        "# load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "wUGtROJfb2Rd",
        "outputId": "2d94306b-0f88-4d2c-facf-70f3dae45ab9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file pretrained-bert/config.json\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"cls_token\": \"[CLS]\",\n",
            "  \"do_lower_case\": true,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mask_token\": \"[MASK]\",\n",
            "  \"max_len\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_max_length\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token\": \"[PAD]\",\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"sep_token\": \"[SEP]\",\n",
            "  \"transformers_version\": \"4.11.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"unk_token\": \"[UNK]\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-20e4fb46ee57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the model checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# load the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                     raise EnvironmentError(\n\u001b[0;32m-> 1267\u001b[0;31m                         \u001b[0;34mf\"Error no file named {[WEIGHTS_NAME, TF2_WEIGHTS_NAME, TF_WEIGHTS_NAME + '.index', FLAX_WEIGHTS_NAME]} found in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m                         \u001b[0;34mf\"directory {pretrained_model_name_or_path} or `from_tf` and `from_flax` set to False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m                     )\n",
            "\u001b[0;31mOSError\u001b[0m: Error no file named ['pytorch_model.bin', 'tf_model.h5', 'model.ckpt.index', 'flax_model.msgpack'] found in directory pretrained-bert or `from_tf` and `from_flax` set to False."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4iWMfz09dOx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "Z3hs0sj9cWNn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform predictions\n",
        "examples = [\n",
        "  \"Today's most trending hashtags on [MASK] is Donald Trump\",\n",
        "  \"The [MASK] was cloudy yesterday, but today it's rainy.\",\n",
        "]\n",
        "for example in examples:\n",
        "  for prediction in fill_mask(example):\n",
        "    print(f\"{prediction['sequence']}, confidence: {prediction['score']}\")\n",
        "  print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h48mtQMcdTZ",
        "outputId": "205acffd-9d8d-4d4c-daaa-dd18e1c4d67a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "today's most trending hashtags on the is donald trump, confidence: 0.004223603755235672\n",
            "today's most trending hashtags on. is donald trump, confidence: 0.0016364316688850522\n",
            "today's most trending hashtags on, is donald trump, confidence: 0.001402979134581983\n",
            "today's most trending hashtags on ballet is donald trump, confidence: 0.0005356564652174711\n",
            "today's most trending hashtags on'is donald trump, confidence: 0.00045132412924431264\n",
            "==================================================\n",
            "the the was cloudy yesterday, but today it's rainy., confidence: 0.004299106076359749\n",
            "the, was cloudy yesterday, but today it's rainy., confidence: 0.0016403653426095843\n",
            "the. was cloudy yesterday, but today it's rainy., confidence: 0.0011256380239501595\n",
            "the ballet was cloudy yesterday, but today it's rainy., confidence: 0.0006522280164062977\n",
            "the'was cloudy yesterday, but today it's rainy., confidence: 0.00048182473983615637\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}